# Machine Learning with NumPy, pandas, scikit-learn, and More
- [Machine Learning with NumPy, pandas, scikit-learn, and More](#machine-learning-with-numpy-pandas-scikit-learn-and-more)
  - [Introduction](#introduction)
  - [Data Modeling with scikit-learn](#data-modeling-with-scikit-learn)
  - [Clustering with scikit-learn](#clustering-with-scikit-learn)
  - [Gradient Boosting with XGBoost](#gradient-boosting-with-xgboost)
  - [Deep Learning with TensorFlow](#deep-learning-with-tensorflow)
  - [Deep Learning with Keras](#deep-learning-with-keras)





Done:

- Machine Learning with NumPy, pandas, scikit-learn, and More
  -  [Data Manipulation with NumPy](Data_Manipulation.md)
  -  [Data Analysis with pandas](Data_Analysis.md)
  -  [Data Preprocessing with scikit-learn](Data_Preprocessing.md)

## Introduction

### What is Machine Learning
We have different type of Machine Learning or ML:
- **Supervised learning**: we label data to train a model. Example a set of handwritten number that already have the right answer tied with the data. (similar to this [summary](https://github.com/Tfloow/Educative/blob/main/Make_your_neural_network))
- **Unsupervised learning**: we let the model make relationships between data. Most data out here are unlabeled. So the goal is not give a precise answer but rather cluster each data together.

### ML vs. AI vs. data science
They do not mean the same. ML is part of AI and AI overlaps with data science. There is also other way to make AI (like alpha-beta pruning, rule-based systems, ...)

### 7 steps of the machine learning process
1. **Data Collection**: one of the most important step to gather good quality data.
2. **Data Processing and Preparation**: make sure it's in the right shape to be fed into our model. (handling missing data, dealing with outliers, errors, ...)
3. **Feature Engineering**: choose to remove some features of the data to optimize the runtime.
4. **Model Selection**: usually we don't start with all new models but rather reuse and tweak some.
5. **Model Training and Data Pipeline**: then we need to choose a data pipeline. Making sure we always have a batch of data ready to be fed.
6. **Model Validation**: we need to use never seen before data by the model so we can test and validate it.
7. **Model Persistence**: then we need to save the crucial part! The



## Data Modeling with scikit-learn

## Clustering with scikit-learn

## Gradient Boosting with XGBoost

## Deep Learning with TensorFlow

## Deep Learning with Keras